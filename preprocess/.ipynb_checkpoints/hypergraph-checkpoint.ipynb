{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "933356a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T05:56:12.901401Z",
     "start_time": "2022-12-26T05:56:11.857319Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# from models.encoder import Encoder, EncoderLayer, ConvLayer, EncoderStack\n",
    "# from models.attn import FullAttention, ProbAttention, AttentionLayer\n",
    "\n",
    "seed = 123456789\n",
    "np.random.seed(seed)\n",
    "\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a60ed7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T06:17:29.003914Z",
     "start_time": "2022-12-26T06:17:28.985082Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [18]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m test \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([[\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m],\n\u001B[0;32m      2\u001B[0m                      [\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m      3\u001B[0m                     [\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m],\n\u001B[0;32m      4\u001B[0m                     [\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m]])\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mall(\u001B[38;5;241m0\u001B[39m \u001B[38;5;241m<\u001B[39m test \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m3\u001B[39m):\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "test = torch.tensor([[0, 1, 2],\n",
    "                     [0, 0, 0],\n",
    "                    [1, 2, 3],\n",
    "                    [0, 0, 0]])\n",
    "if not torch.all(0 < test < 3):\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f5dcd37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T05:33:12.697906Z",
     "start_time": "2022-12-02T05:33:12.693998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "input1 = torch.randn(100, 128)\n",
    "input2 = torch.randn(100, 128)\n",
    "output = F.cosine_similarity(input1, input2, dim=1)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1417b566",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T05:16:33.971818Z",
     "start_time": "2022-12-01T05:16:33.959470Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class EOD_data(Dataset):\n",
    "    def __init__(self, root_path, flag='train', market='NASDAQ', tickers=None, seq_len=4, col_train=None, col_label=None, steps=1):\n",
    "        # init\n",
    "        assert flag in ['train', 'test', 'val']\n",
    "        type_map = {'train':0, 'val':1, 'test':2}\n",
    "        self.col_train = col_train\n",
    "        self.col_label = col_label\n",
    "        self.steps = steps\n",
    "        self.seq_len = seq_len\n",
    "        self.root_path = root_path\n",
    "        self.market = market\n",
    "        self.tickers = tickers\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        for index, ticker in enumerate(self.tickers):\n",
    "            single_EOD = np.genfromtxt(\n",
    "#                 os.path.join(self.root_path, self.market + '_' + ticker + '_1.csv'),\n",
    "                os.path.join(self.root_path, self.market + '_' + ticker + '.csv'),\n",
    "                dtype=np.float32, delimiter=',', skip_header=False)\n",
    "            if self.market == 'NASDAQ':\n",
    "                # remove the last day since lots of missing data\n",
    "                single_EOD = single_EOD[1:, [0, 1, 2, 3, 4, 5, 9, 6, 7, 8]]\n",
    "#                 print(single_EOD.shape, ticker)\n",
    "            if index == 0:\n",
    "                print('single EOD data shape:', single_EOD.shape)  #days*6\n",
    "                self.eod_data = np.zeros([len(self.tickers), single_EOD.shape[0], len(self.col_train)], dtype=np.float32)\n",
    "                self.masks = np.ones([len(self.tickers), single_EOD.shape[0]], dtype=np.int8)\n",
    "                self.ground_truth = np.zeros([len(self.tickers), single_EOD.shape[0], len(self.col_label)], dtype=np.float32)\n",
    "#                 self.base_price = np.zeros([len(self.tickers), single_EOD.shape[0]], dtype=np.float32)\n",
    "            for row in range(single_EOD.shape[0]):\n",
    "                if abs(single_EOD[row][-1] + 1234) < 1e-8:\n",
    "                    self.masks[index][row] = 0.0                         \n",
    "#                 elif row > self.steps - 1 and abs(single_EOD[row - self.steps][-1] + 1234) > 1e-8:\n",
    "#                     self.ground_truth[index][row] = \\\n",
    "#                     (single_EOD[row][-1] - single_EOD[row - self.steps][-1]) / single_EOD[row - self.steps][-1]\n",
    "                for col in range(single_EOD.shape[1]):\n",
    "                    if abs(single_EOD[row][col] + 1234) < 1e-8:\n",
    "                        single_EOD[row][col] = 1\n",
    "            self.eod_data[index, :, :] = single_EOD[:, 1:7]\n",
    "            self.ground_truth[index, :, :] = single_EOD[:, 7:]\n",
    "#             self.base_price[index, :] = single_EOD[:, -1]\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        mask_batch = self.masks[:, index: index + self.seq_len + self.steps]\n",
    "        mask_batch = np.min(mask_batch, axis=1)\n",
    "#         mask_batch = np.expand_dims(mask_batch, axis=1)\n",
    "        seq_x = self.eod_data[:, index:index + self.seq_len, :]\n",
    "        seq_y = self.ground_truth[:, index + self.seq_len + self.steps - 1]\n",
    "#         price_batch = self.base_price[:, index + self.seq_len - 1]\n",
    "#         return seq_x, mask_batch, price_batch, seq_y\n",
    "        return seq_x, mask_batch, seq_y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.eod_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ad8f91a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T05:17:00.231100Z",
     "start_time": "2022-12-01T05:16:59.893976Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hg_test.npy'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 11>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      8\u001B[0m tickers \u001B[38;5;241m=\u001B[39m market_name \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_tickers_qualify_dr-0.98_min-5_smooth.csv\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      9\u001B[0m tickers \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mgenfromtxt(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(data_path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m..\u001B[39m\u001B[38;5;124m'\u001B[39m, tickers),\n\u001B[0;32m     10\u001B[0m                                      dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m, delimiter\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m'\u001B[39m, skip_header\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m---> 11\u001B[0m inci_mat \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mhg_test.npy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m hyp_input \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(inci_mat)\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:390\u001B[0m, in \u001B[0;36mload\u001B[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001B[0m\n\u001B[0;32m    388\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    389\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 390\u001B[0m     fid \u001B[38;5;241m=\u001B[39m stack\u001B[38;5;241m.\u001B[39menter_context(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos_fspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    391\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    393\u001B[0m \u001B[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'hg_test.npy'"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "market_name = 'NASDAQ'\n",
    "# data_path = 'D:/data/qt/data/2013-01-01'\n",
    "data_path = 'D:/data/qt/data/rr8_volumn'\n",
    "col_train = ['rr', 'rr5', 'rr10', 'rr20', 'rr30', 'volumn']\n",
    "col_label = ['rr-1', 'rr-5', 'rr-30']\n",
    "ecod_in = len(col_train)\n",
    "tickers = market_name + '_tickers_qualify_dr-0.98_min-5_smooth.csv'\n",
    "tickers = np.genfromtxt(os.path.join(data_path, '..', tickers),\n",
    "                                     dtype=str, delimiter='\\t', skip_header=False)\n",
    "inci_mat = np.load('hg_test.npy')\n",
    "hyp_input = torch.from_numpy(inci_mat).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97be4db3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T05:16:44.896490Z",
     "start_time": "2022-12-01T05:16:44.879205Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m data_set \u001B[38;5;241m=\u001B[39m EOD_data(root_path\u001B[38;5;241m=\u001B[39m\u001B[43mdata_path\u001B[49m, flag\u001B[38;5;241m=\u001B[39mflag[\u001B[38;5;241m1\u001B[39m], tickers\u001B[38;5;241m=\u001B[39mtickers, col_train\u001B[38;5;241m=\u001B[39mcol_train, col_label\u001B[38;5;241m=\u001B[39mcol_label, seq_len\u001B[38;5;241m=\u001B[39mseq_len)\n\u001B[0;32m      2\u001B[0m train_dataset,validate_dataset,test_dataset\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mrandom_split(data_set,[\u001B[38;5;241m0.4\u001B[39m,\u001B[38;5;241m0.3\u001B[39m,\u001B[38;5;241m0.3\u001B[39m])\n\u001B[0;32m      3\u001B[0m train_loader\u001B[38;5;241m=\u001B[39mDataLoader(train_dataset, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, drop_last\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'data_path' is not defined"
     ]
    }
   ],
   "source": [
    "data_set = EOD_data(root_path=data_path, flag=flag[1], tickers=tickers, col_train=col_train, col_label=col_label, seq_len=seq_len)\n",
    "train_dataset,validate_dataset,test_dataset=torch.utils.data.random_split(data_set,[0.4,0.3,0.3])\n",
    "train_loader=DataLoader(train_dataset, shuffle=True, drop_last=True)\n",
    "validate_loader=DataLoader(validate_dataset, shuffle=True, drop_last=True)\n",
    "test_loader=DataLoader(test_dataset, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "847e8046",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T03:49:18.201793Z",
     "start_time": "2022-12-01T03:49:15.081781Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "for i in range(31):\n",
    "    time.sleep(0.1)\n",
    "end = time.time()\n",
    "int(start - end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33c6798a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T03:52:08.991734Z",
     "start_time": "2022-12-01T03:52:08.987828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:1669866555.083735, end:1669866558.1988616\n"
     ]
    }
   ],
   "source": [
    "print('start:{}, end:{}'.format(start, end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79534926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000, -0.0212],\n",
       "        [-0.0212,  1.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate random array and tensor equivalent\n",
    "x = torch.from_numpy(np.random.rand(1025, 3))\n",
    "y = torch.from_numpy(np.random.rand(1025, 3))\n",
    "\n",
    "# compute corrcoef using those functions\n",
    "z = torch.corrcoef(torch.cat([x[:, 1].unsqueeze(0), y[:, 1].unsqueeze(0)]))\n",
    "\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b923989c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1025, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([x.unsqueeze(0), y.unsqueeze(0)]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6abf1dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_EOD_data(data_path, market_name, tickers, steps=1):\n",
    "    eod_data = []\n",
    "    masks = []\n",
    "    ground_truth = []\n",
    "    base_price = []\n",
    "    for index, ticker in enumerate(tickers):\n",
    "        single_EOD = np.genfromtxt(\n",
    "            os.path.join(data_path, market_name + '_' + ticker + '_1.csv'),\n",
    "            dtype=np.float32, delimiter=',', skip_header=False\n",
    "        )\n",
    "        if market_name == 'NASDAQ':\n",
    "            # remove the last day since lots of missing data\n",
    "            single_EOD = single_EOD[:-1, :]\n",
    "        if index == 0:\n",
    "            print('single EOD data shape:', single_EOD.shape)  #days*6\n",
    "            eod_data = np.zeros([len(tickers), single_EOD.shape[0],\n",
    "                                 single_EOD.shape[1] - 1], dtype=np.float32)\n",
    "            masks = np.ones([len(tickers), single_EOD.shape[0]],   #tickers*days\n",
    "                            dtype=np.float32)\n",
    "            ground_truth = np.zeros([len(tickers), single_EOD.shape[0]],\n",
    "                                    dtype=np.float32)\n",
    "            base_price = np.zeros([len(tickers), single_EOD.shape[0]],\n",
    "                                  dtype=np.float32)\n",
    "        for row in range(single_EOD.shape[0]):\n",
    "            if abs(single_EOD[row][-1] + 1234) < 1e-8:\n",
    "                masks[index][row] = 0.0                         \n",
    "            elif row > steps - 1 and abs(single_EOD[row - steps][-1] + 1234) > 1e-8:\n",
    "                ground_truth[index][row] = \\\n",
    "                (single_EOD[row][-1] - single_EOD[row - steps][-1]) / single_EOD[row - steps][-1]\n",
    "            for col in range(single_EOD.shape[1]):\n",
    "                if abs(single_EOD[row][col] + 1234) < 1e-8:\n",
    "                    single_EOD[row][col] = 1.1\n",
    "        eod_data[index] = single_EOD[:, 1:]\n",
    "        base_price[index] = single_EOD[:, -1]\n",
    "    return eod_data, masks, ground_truth, base_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8c9ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_name = 'NASDAQ'\n",
    "data_path = 'D:/data/qt/data/2013-01-01'\n",
    "tickers = market_name + '_tickers_qualify_dr-0.98_min-5_smooth.csv'\n",
    "tickers = np.genfromtxt(os.path.join(data_path, '..', tickers),\n",
    "                                     dtype=str, delimiter='\\t', skip_header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7efbeb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single EOD data shape: (1245, 6)\n",
      "8 1231\n",
      "8 1232\n",
      "8 1233\n",
      "8 1234\n",
      "8 1235\n",
      "8 1236\n",
      "8 1237\n",
      "8 1238\n",
      "8 1239\n",
      "8 1240\n",
      "8 1241\n",
      "8 1242\n",
      "8 1243\n",
      "8 1244\n",
      "9 0\n",
      "22 37\n",
      "22 38\n",
      "22 134\n",
      "22 135\n",
      "22 151\n",
      "22 152\n",
      "22 223\n",
      "22 224\n",
      "22 230\n",
      "22 231\n",
      "22 374\n",
      "22 375\n",
      "22 378\n",
      "22 379\n",
      "22 587\n",
      "22 588\n",
      "22 919\n",
      "22 920\n",
      "47 746\n",
      "47 747\n",
      "53 0\n",
      "53 17\n",
      "53 18\n",
      "53 50\n",
      "53 51\n",
      "53 121\n",
      "53 122\n",
      "53 320\n",
      "53 321\n",
      "53 322\n",
      "78 790\n",
      "78 791\n",
      "78 904\n",
      "78 905\n",
      "78 924\n",
      "78 925\n",
      "78 957\n",
      "78 958\n",
      "78 959\n",
      "78 960\n",
      "78 993\n",
      "78 994\n",
      "86 29\n",
      "86 30\n",
      "86 51\n",
      "86 52\n",
      "86 85\n",
      "86 86\n",
      "86 142\n",
      "86 143\n",
      "86 536\n",
      "86 537\n",
      "106 0\n",
      "106 23\n",
      "106 24\n",
      "106 26\n",
      "106 27\n",
      "106 35\n",
      "106 36\n",
      "106 37\n",
      "106 38\n",
      "106 57\n",
      "106 58\n",
      "106 162\n",
      "106 163\n",
      "111 500\n",
      "111 501\n",
      "113 223\n",
      "113 224\n",
      "113 730\n",
      "113 731\n",
      "121 0\n",
      "121 30\n",
      "121 31\n",
      "121 69\n",
      "121 70\n",
      "121 75\n",
      "121 76\n",
      "121 88\n",
      "121 89\n",
      "121 113\n",
      "121 114\n",
      "121 132\n",
      "121 133\n",
      "121 356\n",
      "121 357\n",
      "121 469\n",
      "121 470\n",
      "121 483\n",
      "121 484\n",
      "121 485\n",
      "121 486\n",
      "121 555\n",
      "121 556\n",
      "121 615\n",
      "121 616\n",
      "121 617\n",
      "121 674\n",
      "121 675\n",
      "121 678\n",
      "121 679\n",
      "121 697\n",
      "121 698\n",
      "121 718\n",
      "121 719\n",
      "121 720\n",
      "121 721\n",
      "121 773\n",
      "121 774\n",
      "121 787\n",
      "121 788\n",
      "121 818\n",
      "121 819\n",
      "121 971\n",
      "121 972\n",
      "121 992\n",
      "121 993\n",
      "122 1230\n",
      "122 1231\n",
      "122 1232\n",
      "122 1233\n",
      "122 1234\n",
      "122 1235\n",
      "122 1236\n",
      "122 1237\n",
      "122 1238\n",
      "122 1239\n",
      "122 1240\n",
      "122 1241\n",
      "122 1242\n",
      "122 1243\n",
      "122 1244\n",
      "128 521\n",
      "128 522\n",
      "144 499\n",
      "144 500\n",
      "144 784\n",
      "144 785\n",
      "144 801\n",
      "144 802\n",
      "144 945\n",
      "144 946\n",
      "144 960\n",
      "144 961\n",
      "145 0\n",
      "145 1\n",
      "145 2\n",
      "150 1239\n",
      "150 1240\n",
      "150 1241\n",
      "150 1242\n",
      "150 1243\n",
      "150 1244\n",
      "164 542\n",
      "164 543\n",
      "164 583\n",
      "164 584\n",
      "164 604\n",
      "164 605\n",
      "164 608\n",
      "164 609\n",
      "164 653\n",
      "164 654\n",
      "164 661\n",
      "164 662\n",
      "164 700\n",
      "164 701\n",
      "164 714\n",
      "164 715\n",
      "164 730\n",
      "164 731\n",
      "164 735\n",
      "164 736\n",
      "164 843\n",
      "164 844\n",
      "167 0\n",
      "167 1\n",
      "167 2\n",
      "167 3\n",
      "167 4\n",
      "167 5\n",
      "167 6\n",
      "167 7\n",
      "167 8\n",
      "167 9\n",
      "167 10\n",
      "167 11\n",
      "167 12\n",
      "167 13\n",
      "167 14\n",
      "167 15\n",
      "167 16\n",
      "167 17\n",
      "167 18\n",
      "167 19\n",
      "167 20\n",
      "167 21\n",
      "167 22\n",
      "167 23\n",
      "167 24\n",
      "167 25\n",
      "167 26\n",
      "167 27\n",
      "172 0\n",
      "172 1\n",
      "172 2\n",
      "172 3\n",
      "172 4\n",
      "172 5\n",
      "172 6\n",
      "172 7\n",
      "172 8\n",
      "172 9\n",
      "172 10\n",
      "172 11\n",
      "172 12\n",
      "172 13\n",
      "172 14\n",
      "172 15\n",
      "172 16\n",
      "172 17\n",
      "172 18\n",
      "172 19\n",
      "172 20\n",
      "172 21\n",
      "172 22\n",
      "172 23\n",
      "172 24\n",
      "172 25\n",
      "172 26\n",
      "172 27\n",
      "175 983\n",
      "175 984\n",
      "177 0\n",
      "177 1\n",
      "177 2\n",
      "177 3\n",
      "177 4\n",
      "177 5\n",
      "177 6\n",
      "177 7\n",
      "177 8\n",
      "177 9\n",
      "177 10\n",
      "177 11\n",
      "177 12\n",
      "177 13\n",
      "177 14\n",
      "177 15\n",
      "177 16\n",
      "177 17\n",
      "177 18\n",
      "177 19\n",
      "177 20\n",
      "177 21\n",
      "177 22\n",
      "177 23\n",
      "177 24\n",
      "177 25\n",
      "177 26\n",
      "177 27\n",
      "178 0\n",
      "178 1\n",
      "178 2\n",
      "178 3\n",
      "178 4\n",
      "178 5\n",
      "178 6\n",
      "178 7\n",
      "178 8\n",
      "178 9\n",
      "178 10\n",
      "178 11\n",
      "178 12\n",
      "178 13\n",
      "178 14\n",
      "178 15\n",
      "178 16\n",
      "178 17\n",
      "178 18\n",
      "178 19\n",
      "178 20\n",
      "178 21\n",
      "178 22\n",
      "178 23\n",
      "178 24\n",
      "178 25\n",
      "178 26\n",
      "178 27\n",
      "179 628\n",
      "179 629\n",
      "181 1154\n",
      "181 1155\n",
      "182 0\n",
      "182 35\n",
      "182 36\n",
      "182 56\n",
      "182 57\n",
      "182 90\n",
      "182 91\n",
      "182 94\n",
      "182 95\n",
      "182 152\n",
      "182 153\n",
      "182 165\n",
      "182 166\n",
      "182 175\n",
      "182 176\n",
      "182 329\n",
      "182 330\n",
      "182 341\n",
      "182 342\n",
      "182 349\n",
      "182 350\n",
      "182 352\n",
      "182 353\n",
      "182 361\n",
      "182 362\n",
      "182 492\n",
      "182 493\n",
      "182 595\n",
      "182 596\n",
      "182 626\n",
      "182 627\n",
      "182 629\n",
      "182 630\n",
      "182 631\n",
      "182 642\n",
      "182 643\n",
      "182 723\n",
      "182 724\n",
      "182 734\n",
      "182 735\n",
      "182 811\n",
      "182 812\n",
      "182 822\n",
      "182 823\n",
      "182 830\n",
      "182 831\n",
      "207 1154\n",
      "207 1155\n",
      "216 746\n",
      "216 747\n",
      "220 1154\n",
      "220 1155\n",
      "222 335\n",
      "222 336\n",
      "222 603\n",
      "222 604\n",
      "222 648\n",
      "222 649\n",
      "222 650\n",
      "222 651\n",
      "222 704\n",
      "222 705\n",
      "222 836\n",
      "222 837\n",
      "223 0\n",
      "223 1\n",
      "223 2\n",
      "223 3\n",
      "223 4\n",
      "223 5\n",
      "223 6\n",
      "223 7\n",
      "223 8\n",
      "223 9\n",
      "223 10\n",
      "223 11\n",
      "223 12\n",
      "223 13\n",
      "223 14\n",
      "223 15\n",
      "223 16\n",
      "223 17\n",
      "223 18\n",
      "223 19\n",
      "223 20\n",
      "223 21\n",
      "223 22\n",
      "223 23\n",
      "223 24\n",
      "223 25\n",
      "223 26\n",
      "223 27\n",
      "225 749\n",
      "225 750\n",
      "235 223\n",
      "235 224\n",
      "235 295\n",
      "235 296\n",
      "235 300\n",
      "235 301\n",
      "235 540\n",
      "235 541\n",
      "235 604\n",
      "235 605\n",
      "235 610\n",
      "235 611\n",
      "235 619\n",
      "235 620\n",
      "235 643\n",
      "235 644\n",
      "235 647\n",
      "235 648\n",
      "235 686\n",
      "235 687\n",
      "235 699\n",
      "235 700\n",
      "235 712\n",
      "235 713\n",
      "235 753\n",
      "235 754\n",
      "235 758\n",
      "235 759\n",
      "253 501\n",
      "253 502\n",
      "253 624\n",
      "253 625\n",
      "253 673\n",
      "253 674\n",
      "253 721\n",
      "253 722\n",
      "253 725\n",
      "253 726\n",
      "253 751\n",
      "253 752\n",
      "253 829\n",
      "253 830\n",
      "253 837\n",
      "253 838\n",
      "253 854\n",
      "253 855\n",
      "253 895\n",
      "253 896\n",
      "253 967\n",
      "253 968\n",
      "262 501\n",
      "262 502\n",
      "263 1154\n",
      "263 1155\n",
      "264 991\n",
      "264 992\n",
      "264 993\n",
      "264 994\n",
      "264 995\n",
      "264 996\n",
      "264 997\n",
      "264 998\n",
      "264 999\n",
      "264 1000\n",
      "264 1001\n",
      "264 1004\n",
      "264 1005\n",
      "264 1006\n",
      "264 1007\n",
      "264 1015\n",
      "264 1016\n",
      "265 991\n",
      "265 992\n",
      "265 993\n",
      "265 994\n",
      "265 995\n",
      "265 996\n",
      "265 997\n",
      "265 998\n",
      "265 999\n",
      "265 1000\n",
      "265 1001\n",
      "266 1003\n",
      "266 1004\n",
      "267 894\n",
      "267 895\n",
      "275 0\n",
      "275 1\n",
      "275 2\n",
      "275 197\n",
      "275 198\n",
      "275 214\n",
      "275 215\n",
      "275 225\n",
      "275 226\n",
      "275 293\n",
      "275 294\n",
      "275 296\n",
      "275 297\n",
      "275 373\n",
      "275 374\n",
      "280 1154\n",
      "280 1155\n",
      "281 631\n",
      "281 632\n",
      "281 884\n",
      "281 885\n",
      "284 279\n",
      "284 280\n",
      "284 318\n",
      "284 319\n",
      "284 320\n",
      "284 321\n",
      "284 441\n",
      "284 442\n",
      "284 446\n",
      "284 447\n",
      "284 499\n",
      "284 500\n",
      "284 899\n",
      "284 900\n",
      "284 916\n",
      "284 917\n",
      "287 776\n",
      "287 777\n",
      "290 31\n",
      "290 32\n",
      "300 499\n",
      "300 500\n",
      "300 1230\n",
      "300 1231\n",
      "300 1232\n",
      "300 1233\n",
      "300 1234\n",
      "300 1235\n",
      "300 1236\n",
      "300 1237\n",
      "300 1238\n",
      "300 1239\n",
      "300 1240\n",
      "300 1241\n",
      "300 1242\n",
      "300 1243\n",
      "300 1244\n",
      "336 483\n",
      "336 484\n",
      "336 704\n",
      "336 705\n",
      "338 0\n",
      "338 16\n",
      "338 17\n",
      "351 110\n",
      "351 111\n",
      "351 113\n",
      "351 114\n",
      "351 173\n",
      "351 174\n",
      "351 175\n",
      "351 176\n",
      "351 177\n",
      "351 178\n",
      "351 179\n",
      "351 180\n",
      "351 181\n",
      "354 623\n",
      "354 624\n",
      "354 732\n",
      "354 733\n",
      "354 842\n",
      "354 843\n",
      "354 845\n",
      "354 846\n",
      "354 850\n",
      "354 851\n",
      "354 879\n",
      "354 880\n",
      "354 894\n",
      "354 895\n",
      "354 899\n",
      "354 900\n",
      "354 913\n",
      "354 914\n",
      "354 923\n",
      "354 924\n",
      "354 938\n",
      "354 939\n",
      "354 940\n",
      "354 966\n",
      "354 967\n",
      "354 975\n",
      "354 976\n",
      "354 1005\n",
      "354 1006\n",
      "354 1009\n",
      "354 1010\n",
      "354 1019\n",
      "354 1020\n",
      "356 0\n",
      "356 1\n",
      "356 2\n",
      "356 3\n",
      "356 55\n",
      "356 56\n",
      "356 57\n",
      "356 73\n",
      "356 74\n",
      "356 84\n",
      "356 85\n",
      "356 189\n",
      "356 190\n",
      "356 230\n",
      "356 231\n",
      "356 399\n",
      "356 400\n",
      "356 549\n",
      "356 550\n",
      "356 552\n",
      "356 553\n",
      "356 559\n",
      "356 560\n",
      "356 569\n",
      "356 570\n",
      "356 583\n",
      "356 584\n",
      "356 633\n",
      "356 634\n",
      "356 656\n",
      "356 657\n",
      "356 679\n",
      "356 680\n",
      "356 699\n",
      "356 700\n",
      "356 850\n",
      "356 851\n",
      "356 864\n",
      "356 865\n",
      "356 900\n",
      "356 901\n",
      "356 902\n",
      "356 908\n",
      "356 909\n",
      "356 917\n",
      "356 918\n",
      "372 746\n",
      "372 747\n",
      "374 166\n",
      "374 167\n",
      "374 209\n",
      "374 210\n",
      "374 253\n",
      "374 254\n",
      "374 333\n",
      "374 334\n",
      "374 349\n",
      "374 350\n",
      "379 881\n",
      "379 882\n",
      "379 883\n",
      "379 884\n",
      "379 885\n",
      "379 886\n",
      "379 887\n",
      "379 888\n",
      "379 889\n",
      "379 890\n",
      "379 891\n",
      "379 892\n",
      "379 893\n",
      "379 894\n",
      "379 895\n",
      "385 0\n",
      "385 1\n",
      "385 2\n",
      "385 3\n",
      "385 4\n",
      "385 5\n",
      "385 6\n",
      "385 7\n",
      "387 0\n",
      "387 1\n",
      "387 2\n",
      "387 792\n",
      "387 793\n",
      "387 802\n",
      "387 803\n",
      "387 805\n",
      "387 806\n",
      "387 819\n",
      "387 820\n",
      "387 860\n",
      "387 861\n",
      "387 892\n",
      "387 893\n",
      "387 910\n",
      "387 911\n",
      "387 933\n",
      "387 934\n",
      "387 935\n",
      "387 952\n",
      "387 953\n",
      "387 973\n",
      "387 974\n",
      "387 985\n",
      "387 986\n",
      "396 499\n",
      "396 500\n",
      "396 523\n",
      "396 524\n",
      "396 750\n",
      "396 751\n",
      "405 0\n",
      "405 1\n",
      "405 7\n",
      "405 8\n",
      "405 90\n",
      "405 91\n",
      "405 134\n",
      "405 135\n",
      "405 289\n",
      "405 290\n",
      "405 361\n",
      "405 362\n",
      "405 568\n",
      "405 569\n",
      "405 894\n",
      "405 895\n",
      "405 896\n",
      "405 897\n",
      "405 948\n",
      "405 949\n",
      "405 950\n",
      "405 951\n",
      "405 957\n",
      "405 958\n",
      "405 1004\n",
      "405 1005\n",
      "405 1012\n",
      "405 1013\n",
      "415 881\n",
      "415 882\n",
      "415 883\n",
      "415 884\n",
      "415 885\n",
      "415 886\n",
      "415 887\n",
      "415 888\n",
      "415 889\n",
      "415 890\n",
      "415 891\n",
      "415 892\n",
      "415 893\n",
      "415 894\n",
      "415 895\n",
      "444 1154\n",
      "444 1155\n",
      "445 1154\n",
      "445 1155\n",
      "446 0\n",
      "446 1\n",
      "446 2\n",
      "446 3\n",
      "446 4\n",
      "446 5\n",
      "446 6\n",
      "446 7\n",
      "446 8\n",
      "446 9\n",
      "446 10\n",
      "446 11\n",
      "446 12\n",
      "446 13\n",
      "446 14\n",
      "446 15\n",
      "446 16\n",
      "446 17\n",
      "446 18\n",
      "446 19\n",
      "446 20\n",
      "446 21\n",
      "446 22\n",
      "446 23\n",
      "446 24\n",
      "446 25\n",
      "446 26\n",
      "446 27\n",
      "447 40\n",
      "447 41\n",
      "447 62\n",
      "447 63\n",
      "447 129\n",
      "447 130\n",
      "447 131\n",
      "447 132\n",
      "447 176\n",
      "447 177\n",
      "447 195\n",
      "447 196\n",
      "447 208\n",
      "447 209\n",
      "447 219\n",
      "447 220\n",
      "447 247\n",
      "447 248\n",
      "447 277\n",
      "447 278\n",
      "447 310\n",
      "447 311\n",
      "447 498\n",
      "447 499\n",
      "449 776\n",
      "449 777\n",
      "453 1154\n",
      "453 1155\n",
      "459 0\n",
      "459 1\n",
      "459 2\n",
      "459 3\n",
      "459 4\n",
      "459 5\n",
      "459 6\n",
      "459 7\n",
      "459 24\n",
      "459 25\n",
      "459 32\n",
      "459 33\n",
      "459 68\n",
      "459 69\n",
      "459 110\n",
      "459 111\n",
      "467 0\n",
      "467 72\n",
      "467 73\n",
      "467 173\n",
      "467 174\n",
      "467 556\n",
      "467 557\n",
      "480 858\n",
      "480 859\n",
      "482 1154\n",
      "482 1155\n",
      "485 1154\n",
      "485 1155\n",
      "486 1154\n",
      "486 1155\n",
      "494 792\n",
      "494 793\n",
      "503 991\n",
      "503 992\n",
      "503 993\n",
      "503 994\n",
      "503 995\n",
      "503 996\n",
      "503 997\n",
      "503 998\n",
      "503 999\n",
      "503 1000\n",
      "503 1001\n",
      "504 991\n",
      "504 992\n",
      "504 993\n",
      "504 994\n",
      "504 995\n",
      "504 996\n",
      "504 997\n",
      "504 998\n",
      "504 999\n",
      "504 1000\n",
      "505 991\n",
      "505 992\n",
      "505 993\n",
      "505 994\n",
      "505 995\n",
      "505 996\n",
      "505 997\n",
      "505 998\n",
      "505 999\n",
      "505 1000\n",
      "505 1001\n",
      "505 1002\n",
      "505 1003\n",
      "505 1004\n",
      "505 1005\n",
      "505 1006\n",
      "505 1007\n",
      "505 1008\n",
      "506 991\n",
      "506 992\n",
      "506 993\n",
      "506 994\n",
      "506 995\n",
      "506 996\n",
      "506 997\n",
      "506 998\n",
      "506 999\n",
      "506 1000\n",
      "506 1001\n",
      "507 991\n",
      "507 992\n",
      "507 993\n",
      "507 994\n",
      "507 995\n",
      "507 996\n",
      "507 997\n",
      "507 998\n",
      "507 999\n",
      "507 1000\n",
      "519 0\n",
      "519 1\n",
      "519 2\n",
      "519 3\n",
      "519 5\n",
      "519 6\n",
      "519 7\n",
      "519 25\n",
      "519 26\n",
      "519 28\n",
      "519 29\n",
      "519 30\n",
      "519 31\n",
      "519 46\n",
      "519 47\n",
      "519 49\n",
      "519 50\n",
      "519 585\n",
      "519 586\n",
      "519 647\n",
      "519 648\n",
      "519 751\n",
      "519 752\n",
      "531 1230\n",
      "531 1231\n",
      "531 1232\n",
      "531 1233\n",
      "531 1234\n",
      "531 1235\n",
      "531 1236\n",
      "531 1237\n",
      "531 1238\n",
      "531 1239\n",
      "531 1240\n",
      "531 1241\n",
      "531 1242\n",
      "531 1243\n",
      "531 1244\n",
      "554 1154\n",
      "554 1155\n",
      "556 746\n",
      "556 747\n",
      "557 776\n",
      "557 777\n",
      "560 280\n",
      "560 281\n",
      "560 574\n",
      "560 575\n",
      "563 746\n",
      "563 747\n",
      "598 0\n",
      "598 8\n",
      "598 9\n",
      "598 28\n",
      "598 29\n",
      "598 38\n",
      "598 39\n",
      "598 48\n",
      "598 49\n",
      "598 325\n",
      "598 326\n",
      "598 328\n",
      "598 329\n",
      "598 346\n",
      "598 347\n",
      "598 406\n",
      "598 407\n",
      "598 461\n",
      "598 462\n",
      "598 860\n",
      "598 861\n",
      "598 949\n",
      "598 950\n",
      "598 954\n",
      "598 955\n",
      "598 968\n",
      "598 969\n",
      "621 893\n",
      "621 894\n",
      "621 916\n",
      "621 917\n",
      "623 362\n",
      "623 363\n",
      "623 364\n",
      "634 746\n",
      "634 747\n",
      "649 0\n",
      "651 56\n",
      "651 57\n",
      "651 204\n",
      "651 205\n",
      "651 732\n",
      "651 733\n",
      "653 792\n",
      "653 793\n",
      "661 351\n",
      "661 352\n",
      "661 364\n",
      "661 365\n",
      "661 467\n",
      "661 468\n",
      "661 574\n",
      "661 575\n",
      "661 579\n",
      "661 580\n",
      "661 595\n",
      "661 596\n",
      "661 638\n",
      "661 639\n",
      "670 407\n",
      "670 408\n",
      "670 597\n",
      "670 598\n",
      "670 620\n",
      "670 621\n",
      "670 709\n",
      "670 710\n",
      "670 713\n",
      "670 714\n",
      "670 732\n",
      "670 733\n",
      "670 866\n",
      "670 867\n",
      "670 875\n",
      "670 876\n",
      "670 946\n",
      "670 947\n",
      "670 948\n",
      "670 963\n",
      "670 964\n",
      "670 997\n",
      "670 998\n",
      "683 991\n",
      "683 992\n",
      "683 993\n",
      "683 994\n",
      "683 995\n",
      "683 996\n",
      "683 997\n",
      "683 998\n",
      "683 999\n",
      "683 1000\n",
      "683 1001\n",
      "688 991\n",
      "688 992\n",
      "688 993\n",
      "688 994\n",
      "688 995\n",
      "688 996\n",
      "688 997\n",
      "688 998\n",
      "688 999\n",
      "688 1000\n",
      "688 1001\n",
      "689 991\n",
      "689 992\n",
      "689 993\n",
      "689 994\n",
      "689 995\n",
      "689 996\n",
      "689 997\n",
      "689 998\n",
      "689 999\n",
      "689 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692 1154\n",
      "692 1155\n",
      "693 991\n",
      "693 992\n",
      "693 993\n",
      "693 994\n",
      "693 995\n",
      "693 996\n",
      "693 997\n",
      "693 998\n",
      "693 999\n",
      "693 1000\n",
      "694 292\n",
      "694 293\n",
      "694 332\n",
      "694 333\n",
      "694 436\n",
      "694 437\n",
      "694 460\n",
      "694 461\n",
      "694 489\n",
      "694 490\n",
      "694 533\n",
      "694 534\n",
      "694 546\n",
      "694 547\n",
      "694 562\n",
      "694 563\n",
      "694 623\n",
      "694 624\n",
      "694 677\n",
      "694 678\n",
      "694 698\n",
      "694 699\n",
      "694 899\n",
      "694 900\n",
      "694 958\n",
      "694 959\n",
      "694 960\n",
      "694 961\n",
      "694 962\n",
      "694 964\n",
      "694 965\n",
      "694 1005\n",
      "694 1006\n",
      "696 991\n",
      "696 992\n",
      "696 993\n",
      "696 994\n",
      "696 995\n",
      "696 996\n",
      "696 997\n",
      "696 998\n",
      "696 999\n",
      "696 1000\n",
      "696 1001\n",
      "699 991\n",
      "699 992\n",
      "699 993\n",
      "699 994\n",
      "699 995\n",
      "699 996\n",
      "699 997\n",
      "699 998\n",
      "699 999\n",
      "699 1000\n",
      "699 1001\n",
      "701 991\n",
      "701 992\n",
      "701 993\n",
      "701 994\n",
      "701 995\n",
      "701 996\n",
      "701 997\n",
      "701 998\n",
      "701 999\n",
      "701 1000\n",
      "701 1001\n",
      "703 991\n",
      "703 992\n",
      "703 993\n",
      "703 994\n",
      "703 995\n",
      "703 996\n",
      "703 997\n",
      "703 998\n",
      "703 999\n",
      "703 1000\n",
      "703 1001\n",
      "704 991\n",
      "704 992\n",
      "704 993\n",
      "704 994\n",
      "704 995\n",
      "704 996\n",
      "704 997\n",
      "704 998\n",
      "704 999\n",
      "704 1000\n",
      "704 1001\n",
      "705 991\n",
      "705 992\n",
      "705 993\n",
      "705 994\n",
      "705 995\n",
      "705 996\n",
      "705 997\n",
      "705 998\n",
      "705 999\n",
      "705 1000\n",
      "705 1001\n",
      "706 991\n",
      "706 992\n",
      "706 993\n",
      "706 994\n",
      "706 995\n",
      "706 996\n",
      "706 997\n",
      "706 998\n",
      "706 999\n",
      "706 1000\n",
      "706 1001\n",
      "706 1002\n",
      "706 1003\n",
      "706 1004\n",
      "706 1005\n",
      "706 1006\n",
      "706 1007\n",
      "706 1008\n",
      "708 991\n",
      "708 992\n",
      "708 993\n",
      "708 994\n",
      "708 995\n",
      "708 996\n",
      "708 997\n",
      "708 998\n",
      "708 999\n",
      "708 1000\n",
      "708 1001\n",
      "713 991\n",
      "713 992\n",
      "713 993\n",
      "713 994\n",
      "713 995\n",
      "713 996\n",
      "713 997\n",
      "713 998\n",
      "713 999\n",
      "713 1000\n",
      "713 1001\n",
      "713 1002\n",
      "713 1003\n",
      "713 1004\n",
      "713 1005\n",
      "713 1006\n",
      "713 1007\n",
      "715 383\n",
      "715 384\n",
      "715 387\n",
      "715 388\n",
      "715 571\n",
      "715 572\n",
      "715 664\n",
      "715 665\n",
      "722 746\n",
      "722 747\n",
      "724 0\n",
      "725 775\n",
      "725 776\n",
      "731 991\n",
      "731 992\n",
      "731 993\n",
      "731 994\n",
      "731 995\n",
      "731 996\n",
      "731 997\n",
      "731 998\n",
      "731 999\n",
      "731 1000\n",
      "733 746\n",
      "733 747\n",
      "734 0\n",
      "734 1\n",
      "734 2\n",
      "734 3\n",
      "734 4\n",
      "734 5\n",
      "734 6\n",
      "734 7\n",
      "734 8\n",
      "734 9\n",
      "734 10\n",
      "734 11\n",
      "734 12\n",
      "734 13\n",
      "734 14\n",
      "734 15\n",
      "734 16\n",
      "734 17\n",
      "734 18\n",
      "734 19\n",
      "734 20\n",
      "734 21\n",
      "734 22\n",
      "737 325\n",
      "737 326\n",
      "737 443\n",
      "737 444\n",
      "737 562\n",
      "737 563\n",
      "737 647\n",
      "737 648\n",
      "737 654\n",
      "737 655\n",
      "739 81\n",
      "739 82\n",
      "739 123\n",
      "739 124\n",
      "742 659\n",
      "742 660\n",
      "742 717\n",
      "742 718\n",
      "742 901\n",
      "742 902\n",
      "744 226\n",
      "744 227\n",
      "744 332\n",
      "744 333\n",
      "744 335\n",
      "744 336\n",
      "744 591\n",
      "744 592\n",
      "744 656\n",
      "744 657\n",
      "744 675\n",
      "744 676\n",
      "744 688\n",
      "744 689\n",
      "746 991\n",
      "746 992\n",
      "746 993\n",
      "746 994\n",
      "746 995\n",
      "746 996\n",
      "746 997\n",
      "746 998\n",
      "746 999\n",
      "746 1000\n",
      "748 1239\n",
      "748 1240\n",
      "748 1241\n",
      "748 1242\n",
      "748 1243\n",
      "748 1244\n",
      "751 991\n",
      "751 992\n",
      "751 993\n",
      "751 994\n",
      "751 995\n",
      "751 996\n",
      "751 997\n",
      "751 998\n",
      "751 999\n",
      "751 1000\n",
      "752 991\n",
      "752 992\n",
      "752 993\n",
      "752 994\n",
      "752 995\n",
      "752 996\n",
      "752 997\n",
      "752 998\n",
      "752 999\n",
      "752 1000\n",
      "753 0\n",
      "753 1\n",
      "753 2\n",
      "753 8\n",
      "753 9\n",
      "753 25\n",
      "753 26\n",
      "753 58\n",
      "753 59\n",
      "753 61\n",
      "753 62\n",
      "753 64\n",
      "753 65\n",
      "753 71\n",
      "753 72\n",
      "753 74\n",
      "753 75\n",
      "753 83\n",
      "753 84\n",
      "753 92\n",
      "753 93\n",
      "753 111\n",
      "753 112\n",
      "753 117\n",
      "753 118\n",
      "753 140\n",
      "753 141\n",
      "754 991\n",
      "754 992\n",
      "754 993\n",
      "754 994\n",
      "754 995\n",
      "754 996\n",
      "754 997\n",
      "754 998\n",
      "754 999\n",
      "754 1000\n",
      "755 919\n",
      "755 920\n",
      "756 991\n",
      "756 992\n",
      "756 993\n",
      "756 994\n",
      "756 995\n",
      "756 996\n",
      "756 997\n",
      "756 998\n",
      "756 999\n",
      "756 1000\n",
      "757 991\n",
      "757 992\n",
      "757 993\n",
      "757 994\n",
      "757 995\n",
      "757 996\n",
      "757 997\n",
      "757 998\n",
      "757 999\n",
      "757 1000\n",
      "759 0\n",
      "759 8\n",
      "759 9\n",
      "763 7\n",
      "763 8\n",
      "763 31\n",
      "763 32\n",
      "763 56\n",
      "763 57\n",
      "763 58\n",
      "763 77\n",
      "763 78\n",
      "763 100\n",
      "763 101\n",
      "763 120\n",
      "763 121\n",
      "763 160\n",
      "763 161\n",
      "763 210\n",
      "763 211\n",
      "763 499\n",
      "763 500\n",
      "782 612\n",
      "782 613\n",
      "786 1154\n",
      "786 1155\n",
      "797 0\n",
      "797 1\n",
      "797 4\n",
      "797 5\n",
      "797 55\n",
      "797 56\n",
      "797 155\n",
      "797 156\n",
      "797 182\n",
      "797 183\n",
      "797 422\n",
      "797 423\n",
      "797 527\n",
      "797 528\n",
      "797 538\n",
      "797 539\n",
      "817 776\n",
      "817 777\n",
      "822 0\n",
      "822 5\n",
      "822 6\n",
      "822 7\n",
      "822 12\n",
      "822 13\n",
      "822 31\n",
      "822 32\n",
      "822 51\n",
      "822 52\n",
      "822 54\n",
      "822 55\n",
      "822 57\n",
      "822 58\n",
      "822 80\n",
      "822 81\n",
      "822 93\n",
      "822 94\n",
      "822 97\n",
      "822 98\n",
      "822 126\n",
      "822 127\n",
      "824 57\n",
      "824 58\n",
      "824 65\n",
      "824 66\n",
      "824 71\n",
      "824 72\n",
      "824 324\n",
      "824 325\n",
      "824 345\n",
      "824 346\n",
      "824 447\n",
      "824 448\n",
      "824 458\n",
      "824 459\n",
      "824 484\n",
      "824 485\n",
      "824 493\n",
      "824 494\n",
      "824 511\n",
      "824 512\n",
      "824 516\n",
      "824 517\n",
      "824 539\n",
      "824 540\n",
      "824 607\n",
      "824 608\n",
      "824 633\n",
      "824 634\n",
      "824 644\n",
      "824 645\n",
      "824 721\n",
      "824 722\n",
      "829 1154\n",
      "829 1155\n",
      "830 1154\n",
      "830 1155\n",
      "831 349\n",
      "831 350\n",
      "831 469\n",
      "831 470\n",
      "831 600\n",
      "831 601\n",
      "831 647\n",
      "831 648\n",
      "836 881\n",
      "836 882\n",
      "836 883\n",
      "836 884\n",
      "836 885\n",
      "836 886\n",
      "836 887\n",
      "836 888\n",
      "836 889\n",
      "836 890\n",
      "836 891\n",
      "836 892\n",
      "836 893\n",
      "836 894\n",
      "836 895\n",
      "848 881\n",
      "848 882\n",
      "848 883\n",
      "848 884\n",
      "848 885\n",
      "848 886\n",
      "848 887\n",
      "848 888\n",
      "848 889\n",
      "848 890\n",
      "848 891\n",
      "848 892\n",
      "848 893\n",
      "848 894\n",
      "848 895\n",
      "850 746\n",
      "850 747\n",
      "851 126\n",
      "851 127\n",
      "854 168\n",
      "854 169\n",
      "854 249\n",
      "854 250\n",
      "854 278\n",
      "854 279\n",
      "854 330\n",
      "854 331\n",
      "854 353\n",
      "854 354\n",
      "854 367\n",
      "854 368\n",
      "854 381\n",
      "854 382\n",
      "854 385\n",
      "854 386\n",
      "854 392\n",
      "854 393\n",
      "854 394\n",
      "854 395\n",
      "854 405\n",
      "854 406\n",
      "854 407\n",
      "854 408\n",
      "854 412\n",
      "854 413\n",
      "854 419\n",
      "854 420\n",
      "854 479\n",
      "854 480\n",
      "854 504\n",
      "854 505\n",
      "854 569\n",
      "854 570\n",
      "854 600\n",
      "854 601\n",
      "857 746\n",
      "857 747\n",
      "858 855\n",
      "858 856\n",
      "868 0\n",
      "868 1\n",
      "868 2\n",
      "868 3\n",
      "868 4\n",
      "868 5\n",
      "868 6\n",
      "868 7\n",
      "868 8\n",
      "868 9\n",
      "876 1\n",
      "876 2\n",
      "876 230\n",
      "876 231\n",
      "886 56\n",
      "886 57\n",
      "888 22\n",
      "888 23\n",
      "888 481\n",
      "888 482\n",
      "889 0\n",
      "895 250\n",
      "895 251\n",
      "921 1154\n",
      "921 1155\n",
      "931 0\n",
      "931 1\n",
      "931 2\n",
      "931 3\n",
      "931 4\n",
      "931 5\n",
      "931 6\n",
      "931 7\n",
      "931 8\n",
      "931 9\n",
      "931 10\n",
      "931 11\n",
      "931 12\n",
      "931 13\n",
      "931 14\n",
      "931 15\n",
      "931 16\n",
      "931 17\n",
      "931 18\n",
      "931 19\n",
      "931 20\n",
      "931 21\n",
      "931 22\n",
      "931 23\n",
      "931 24\n",
      "931 25\n",
      "931 26\n",
      "931 27\n",
      "937 0\n",
      "937 6\n",
      "937 7\n",
      "937 126\n",
      "937 127\n",
      "937 183\n",
      "937 184\n",
      "937 198\n",
      "937 199\n",
      "937 204\n",
      "937 205\n",
      "937 281\n",
      "937 282\n",
      "937 310\n",
      "937 311\n",
      "937 429\n",
      "937 430\n",
      "937 530\n",
      "937 531\n",
      "937 533\n",
      "937 534\n",
      "937 591\n",
      "937 592\n",
      "937 648\n",
      "937 649\n",
      "937 751\n",
      "937 752\n",
      "940 0\n",
      "940 1\n",
      "940 2\n",
      "940 3\n",
      "940 4\n",
      "960 188\n",
      "960 189\n",
      "971 0\n",
      "971 746\n",
      "971 747\n",
      "978 593\n",
      "978 594\n",
      "981 0\n",
      "981 76\n",
      "981 77\n",
      "981 130\n",
      "981 131\n",
      "981 140\n",
      "981 141\n",
      "981 142\n",
      "981 158\n",
      "981 159\n",
      "981 191\n",
      "981 192\n",
      "981 197\n",
      "981 198\n",
      "981 330\n",
      "981 331\n",
      "981 382\n",
      "981 383\n",
      "981 720\n",
      "981 721\n",
      "985 0\n",
      "985 366\n",
      "985 367\n",
      "985 418\n",
      "985 419\n",
      "985 704\n",
      "985 705\n",
      "997 0\n",
      "997 1\n",
      "997 2\n",
      "997 3\n",
      "997 4\n",
      "997 5\n",
      "997 6\n",
      "997 7\n",
      "997 8\n",
      "997 9\n",
      "997 10\n",
      "1008 601\n",
      "1008 602\n",
      "1008 708\n",
      "1008 709\n",
      "1008 851\n",
      "1008 852\n",
      "1020 0\n",
      "1020 1\n"
     ]
    }
   ],
   "source": [
    "eod_data, masks, ground_truth, base_price = load_EOD_data(data_path, market_name, tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "49fc5bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1026, 1245)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b888a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1026, 1245)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_price.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "abc74b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1026, 1245, 5)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eod_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d0beabb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1026, 1245)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a95f960",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_test = np.load('./training/hg_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd49e4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2518"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_test[1].max().item() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38526994",
   "metadata": {},
   "outputs": [],
   "source": [
    "industry = r\"C:\\Users\\kikyo\\code\\qt\\sthan-sr-aaai-main\\training\\NASDAQ_industry_relation.npy\"\n",
    "wiki = r\"C:\\Users\\kikyo\\code\\qt\\sthan-sr-aaai-main\\training\\NASDAQ_wiki_relation.npy\"\n",
    "npy = np.load(wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c3536f9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 43/43 [00:01<00:00, 26.58it/s]\n"
     ]
    }
   ],
   "source": [
    "row = []\n",
    "col = []\n",
    "edge = -1\n",
    "for i in tqdm(range(43)):         \n",
    "    local = utils.from_scipy_sparse_matrix(coo_matrix(npy[:, :, i]))\n",
    "    node0 = 0\n",
    "    for j in range(len(local[0][0])):\n",
    "        if local[0][0][j] != node0:\n",
    "            node0 = local[0][0][j]\n",
    "            row.append(node0)\n",
    "            edge += 1\n",
    "        else:\n",
    "            row.append(local[0][1][j])\n",
    "        col.append(edge)\n",
    "hg = np.array([np.array(row), col])\n",
    "# np.save(r\"C:\\Users\\kikyo\\code\\qt\\sthan-sr-aaai-main\\training\\hg_test\", hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a4ef109b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159188,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(row).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed2b953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t2\n",
      "  (0, 4)\t2\n",
      "  (0, 5)\t3\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t2\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t3\n",
      "  (1, 5)\t2\n"
     ]
    }
   ],
   "source": [
    "edge_index = torch.tensor([\n",
    "    [0, 1, 1, 2, 2, 3],\n",
    "    [1, 0, 2, 1, 3, 2],\n",
    "])\n",
    "# print(utils.to_scipy_sparse_matrix(edge_index))\n",
    "print(coo_matrix(edge_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25e0cf8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 1, 2, 2],\n",
       "         [1, 2, 2, 0, 1]]),\n",
       " tensor([1, 1, 1, 1, 1], dtype=torch.int32))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[0, 1, 1],[0, 0, 1], [1, 1 ,0]])\n",
    "utils.from_scipy_sparse_matrix(coo_matrix(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b4a8b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on coo_matrix in module scipy.sparse._coo object:\n",
      "\n",
      "class coo_matrix(scipy.sparse._data._data_matrix, scipy.sparse._data._minmax_mixin)\n",
      " |  coo_matrix(arg1, shape=None, dtype=None, copy=False)\n",
      " |  \n",
      " |  A sparse matrix in COOrdinate format.\n",
      " |  \n",
      " |  Also known as the 'ijv' or 'triplet' format.\n",
      " |  \n",
      " |  This can be instantiated in several ways:\n",
      " |      coo_matrix(D)\n",
      " |          with a dense matrix D\n",
      " |  \n",
      " |      coo_matrix(S)\n",
      " |          with another sparse matrix S (equivalent to S.tocoo())\n",
      " |  \n",
      " |      coo_matrix((M, N), [dtype])\n",
      " |          to construct an empty matrix with shape (M, N)\n",
      " |          dtype is optional, defaulting to dtype='d'.\n",
      " |  \n",
      " |      coo_matrix((data, (i, j)), [shape=(M, N)])\n",
      " |          to construct from three arrays:\n",
      " |              1. data[:]   the entries of the matrix, in any order\n",
      " |              2. i[:]      the row indices of the matrix entries\n",
      " |              3. j[:]      the column indices of the matrix entries\n",
      " |  \n",
      " |          Where ``A[i[k], j[k]] = data[k]``.  When shape is not\n",
      " |          specified, it is inferred from the index arrays\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  dtype : dtype\n",
      " |      Data type of the matrix\n",
      " |  shape : 2-tuple\n",
      " |      Shape of the matrix\n",
      " |  ndim : int\n",
      " |      Number of dimensions (this is always 2)\n",
      " |  nnz\n",
      " |      Number of stored values, including explicit zeros\n",
      " |  data\n",
      " |      COO format data array of the matrix\n",
      " |  row\n",
      " |      COO format row index array of the matrix\n",
      " |  col\n",
      " |      COO format column index array of the matrix\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  \n",
      " |  Sparse matrices can be used in arithmetic operations: they support\n",
      " |  addition, subtraction, multiplication, division, and matrix power.\n",
      " |  \n",
      " |  Advantages of the COO format\n",
      " |      - facilitates fast conversion among sparse formats\n",
      " |      - permits duplicate entries (see example)\n",
      " |      - very fast conversion to and from CSR/CSC formats\n",
      " |  \n",
      " |  Disadvantages of the COO format\n",
      " |      - does not directly support:\n",
      " |          + arithmetic operations\n",
      " |          + slicing\n",
      " |  \n",
      " |  Intended Usage\n",
      " |      - COO is a fast format for constructing sparse matrices\n",
      " |      - Once a matrix has been constructed, convert to CSR or\n",
      " |        CSC format for fast arithmetic and matrix vector operations\n",
      " |      - By default when converting to CSR or CSC format, duplicate (i,j)\n",
      " |        entries will be summed together.  This facilitates efficient\n",
      " |        construction of finite element matrices and the like. (see example)\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  \n",
      " |  >>> # Constructing an empty matrix\n",
      " |  >>> from scipy.sparse import coo_matrix\n",
      " |  >>> coo_matrix((3, 4), dtype=np.int8).toarray()\n",
      " |  array([[0, 0, 0, 0],\n",
      " |         [0, 0, 0, 0],\n",
      " |         [0, 0, 0, 0]], dtype=int8)\n",
      " |  \n",
      " |  >>> # Constructing a matrix using ijv format\n",
      " |  >>> row  = np.array([0, 3, 1, 0])\n",
      " |  >>> col  = np.array([0, 3, 1, 2])\n",
      " |  >>> data = np.array([4, 5, 7, 9])\n",
      " |  >>> coo_matrix((data, (row, col)), shape=(4, 4)).toarray()\n",
      " |  array([[4, 0, 9, 0],\n",
      " |         [0, 7, 0, 0],\n",
      " |         [0, 0, 0, 0],\n",
      " |         [0, 0, 0, 5]])\n",
      " |  \n",
      " |  >>> # Constructing a matrix with duplicate indices\n",
      " |  >>> row  = np.array([0, 0, 1, 3, 1, 0, 0])\n",
      " |  >>> col  = np.array([0, 2, 1, 3, 1, 0, 0])\n",
      " |  >>> data = np.array([1, 1, 1, 1, 1, 1, 1])\n",
      " |  >>> coo = coo_matrix((data, (row, col)), shape=(4, 4))\n",
      " |  >>> # Duplicate indices are maintained until implicitly or explicitly summed\n",
      " |  >>> np.max(coo.data)\n",
      " |  1\n",
      " |  >>> coo.toarray()\n",
      " |  array([[3, 0, 1, 0],\n",
      " |         [0, 2, 0, 0],\n",
      " |         [0, 0, 0, 0],\n",
      " |         [0, 0, 0, 1]])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      coo_matrix\n",
      " |      scipy.sparse._data._data_matrix\n",
      " |      scipy.sparse._base.spmatrix\n",
      " |      scipy.sparse._data._minmax_mixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, arg1, shape=None, dtype=None, copy=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  diagonal(self, k=0)\n",
      " |      Returns the kth diagonal of the matrix.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      k : int, optional\n",
      " |          Which diagonal to get, corresponding to elements a[i, i+k].\n",
      " |          Default: 0 (the main diagonal).\n",
      " |      \n",
      " |          .. versionadded:: 1.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.diagonal : Equivalent numpy function.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from scipy.sparse import csr_matrix\n",
      " |      >>> A = csr_matrix([[1, 2, 0], [0, 0, 3], [4, 0, 5]])\n",
      " |      >>> A.diagonal()\n",
      " |      array([1, 0, 5])\n",
      " |      >>> A.diagonal(k=1)\n",
      " |      array([2, 3])\n",
      " |  \n",
      " |  eliminate_zeros(self)\n",
      " |      Remove zero entries from the matrix\n",
      " |      \n",
      " |      This is an *in place* operation\n",
      " |  \n",
      " |  getnnz(self, axis=None)\n",
      " |      Number of stored values, including explicit zeros.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : None, 0, or 1\n",
      " |          Select between the number of values across the whole matrix, in\n",
      " |          each column, or in each row.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      count_nonzero : Number of non-zero entries\n",
      " |  \n",
      " |  reshape(self, *args, **kwargs)\n",
      " |      reshape(self, shape, order='C', copy=False)\n",
      " |      \n",
      " |      Gives a new shape to a sparse matrix without changing its data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      shape : length-2 tuple of ints\n",
      " |          The new shape should be compatible with the original shape.\n",
      " |      order : {'C', 'F'}, optional\n",
      " |          Read the elements using this index order. 'C' means to read and\n",
      " |          write the elements using C-like index order; e.g., read entire first\n",
      " |          row, then second row, etc. 'F' means to read and write the elements\n",
      " |          using Fortran-like index order; e.g., read entire first column, then\n",
      " |          second column, etc.\n",
      " |      copy : bool, optional\n",
      " |          Indicates whether or not attributes of self should be copied\n",
      " |          whenever possible. The degree to which attributes are copied varies\n",
      " |          depending on the type of sparse matrix being used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reshaped_matrix : sparse matrix\n",
      " |          A sparse matrix with the given `shape`, not necessarily of the same\n",
      " |          format as the current object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.matrix.reshape : NumPy's implementation of 'reshape' for\n",
      " |                             matrices\n",
      " |  \n",
      " |  resize(self, *shape)\n",
      " |      Resize the matrix in-place to dimensions given by ``shape``\n",
      " |      \n",
      " |      Any elements that lie within the new shape will remain at the same\n",
      " |      indices, while non-zero elements lying outside the new shape are\n",
      " |      removed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      shape : (int, int)\n",
      " |          number of rows and columns in the new matrix\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The semantics are not identical to `numpy.ndarray.resize` or\n",
      " |      `numpy.resize`. Here, the same data will be maintained at each index\n",
      " |      before and after reshape, if that index is within the new bounds. In\n",
      " |      numpy, resizing maintains contiguity of the array, moving elements\n",
      " |      around in the logical matrix but not within a flattened representation.\n",
      " |      \n",
      " |      We give no guarantees about whether the underlying data attributes\n",
      " |      (arrays, etc.) will be modified in place or replaced with new objects.\n",
      " |  \n",
      " |  sum_duplicates(self)\n",
      " |      Eliminate duplicate matrix entries by adding them together\n",
      " |      \n",
      " |      This is an *in place* operation\n",
      " |  \n",
      " |  toarray(self, order=None, out=None)\n",
      " |      See the docstring for `spmatrix.toarray`.\n",
      " |  \n",
      " |  tocoo(self, copy=False)\n",
      " |      Convert this matrix to COOrdinate format.\n",
      " |      \n",
      " |      With copy=False, the data/indices may be shared between this matrix and\n",
      " |      the resultant coo_matrix.\n",
      " |  \n",
      " |  tocsc(self, copy=False)\n",
      " |      Convert this matrix to Compressed Sparse Column format\n",
      " |      \n",
      " |      Duplicate entries will be summed together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from numpy import array\n",
      " |      >>> from scipy.sparse import coo_matrix\n",
      " |      >>> row  = array([0, 0, 1, 3, 1, 0, 0])\n",
      " |      >>> col  = array([0, 2, 1, 3, 1, 0, 0])\n",
      " |      >>> data = array([1, 1, 1, 1, 1, 1, 1])\n",
      " |      >>> A = coo_matrix((data, (row, col)), shape=(4, 4)).tocsc()\n",
      " |      >>> A.toarray()\n",
      " |      array([[3, 0, 1, 0],\n",
      " |             [0, 2, 0, 0],\n",
      " |             [0, 0, 0, 0],\n",
      " |             [0, 0, 0, 1]])\n",
      " |  \n",
      " |  tocsr(self, copy=False)\n",
      " |      Convert this matrix to Compressed Sparse Row format\n",
      " |      \n",
      " |      Duplicate entries will be summed together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from numpy import array\n",
      " |      >>> from scipy.sparse import coo_matrix\n",
      " |      >>> row  = array([0, 0, 1, 3, 1, 0, 0])\n",
      " |      >>> col  = array([0, 2, 1, 3, 1, 0, 0])\n",
      " |      >>> data = array([1, 1, 1, 1, 1, 1, 1])\n",
      " |      >>> A = coo_matrix((data, (row, col)), shape=(4, 4)).tocsr()\n",
      " |      >>> A.toarray()\n",
      " |      array([[3, 0, 1, 0],\n",
      " |             [0, 2, 0, 0],\n",
      " |             [0, 0, 0, 0],\n",
      " |             [0, 0, 0, 1]])\n",
      " |  \n",
      " |  todia(self, copy=False)\n",
      " |      Convert this matrix to sparse DIAgonal format.\n",
      " |      \n",
      " |      With copy=False, the data/indices may be shared between this matrix and\n",
      " |      the resultant dia_matrix.\n",
      " |  \n",
      " |  todok(self, copy=False)\n",
      " |      Convert this matrix to Dictionary Of Keys format.\n",
      " |      \n",
      " |      With copy=False, the data/indices may be shared between this matrix and\n",
      " |      the resultant dok_matrix.\n",
      " |  \n",
      " |  transpose(self, axes=None, copy=False)\n",
      " |      Reverses the dimensions of the sparse matrix.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axes : None, optional\n",
      " |          This argument is in the signature *solely* for NumPy\n",
      " |          compatibility reasons. Do not pass in anything except\n",
      " |          for the default value.\n",
      " |      copy : bool, optional\n",
      " |          Indicates whether or not attributes of `self` should be\n",
      " |          copied whenever possible. The degree to which attributes\n",
      " |          are copied varies depending on the type of sparse matrix\n",
      " |          being used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : `self` with the dimensions reversed.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.matrix.transpose : NumPy's implementation of 'transpose'\n",
      " |                               for matrices\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  format = 'coo'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.sparse._data._data_matrix:\n",
      " |  \n",
      " |  __abs__(self)\n",
      " |  \n",
      " |  __imul__(self, other)\n",
      " |  \n",
      " |  __itruediv__(self, other)\n",
      " |  \n",
      " |  __neg__(self)\n",
      " |  \n",
      " |  __round__(self, ndigits=0)\n",
      " |  \n",
      " |  arcsin(self)\n",
      " |      Element-wise arcsin.\n",
      " |      \n",
      " |      See `numpy.arcsin` for more information.\n",
      " |  \n",
      " |  arcsinh(self)\n",
      " |      Element-wise arcsinh.\n",
      " |      \n",
      " |      See `numpy.arcsinh` for more information.\n",
      " |  \n",
      " |  arctan(self)\n",
      " |      Element-wise arctan.\n",
      " |      \n",
      " |      See `numpy.arctan` for more information.\n",
      " |  \n",
      " |  arctanh(self)\n",
      " |      Element-wise arctanh.\n",
      " |      \n",
      " |      See `numpy.arctanh` for more information.\n",
      " |  \n",
      " |  astype(self, dtype, casting='unsafe', copy=True)\n",
      " |      Cast the matrix elements to a specified type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : string or numpy dtype\n",
      " |          Typecode or data-type to which to cast the data.\n",
      " |      casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      " |          Controls what kind of data casting may occur.\n",
      " |          Defaults to 'unsafe' for backwards compatibility.\n",
      " |          'no' means the data types should not be cast at all.\n",
      " |          'equiv' means only byte-order changes are allowed.\n",
      " |          'safe' means only casts which can preserve values are allowed.\n",
      " |          'same_kind' means only safe casts or casts within a kind,\n",
      " |          like float64 to float32, are allowed.\n",
      " |          'unsafe' means any data conversions may be done.\n",
      " |      copy : bool, optional\n",
      " |          If `copy` is `False`, the result might share some memory with this\n",
      " |          matrix. If `copy` is `True`, it is guaranteed that the result and\n",
      " |          this matrix do not share any memory.\n",
      " |  \n",
      " |  ceil(self)\n",
      " |      Element-wise ceil.\n",
      " |      \n",
      " |      See `numpy.ceil` for more information.\n",
      " |  \n",
      " |  conj(self, copy=True)\n",
      " |      Element-wise complex conjugation.\n",
      " |      \n",
      " |      If the matrix is of non-complex data type and `copy` is False,\n",
      " |      this method does nothing and the data is not copied.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : bool, optional\n",
      " |          If True, the result is guaranteed to not share data with self.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A : The element-wise complex conjugate.\n",
      " |  \n",
      " |  copy(self)\n",
      " |      Returns a copy of this matrix.\n",
      " |      \n",
      " |      No data/indices will be shared between the returned value and current\n",
      " |      matrix.\n",
      " |  \n",
      " |  count_nonzero(self)\n",
      " |      Number of non-zero entries, equivalent to\n",
      " |      \n",
      " |      np.count_nonzero(a.toarray())\n",
      " |      \n",
      " |      Unlike getnnz() and the nnz property, which return the number of stored\n",
      " |      entries (the length of the data attribute), this method counts the\n",
      " |      actual number of non-zero entries in data.\n",
      " |  \n",
      " |  deg2rad(self)\n",
      " |      Element-wise deg2rad.\n",
      " |      \n",
      " |      See `numpy.deg2rad` for more information.\n",
      " |  \n",
      " |  expm1(self)\n",
      " |      Element-wise expm1.\n",
      " |      \n",
      " |      See `numpy.expm1` for more information.\n",
      " |  \n",
      " |  floor(self)\n",
      " |      Element-wise floor.\n",
      " |      \n",
      " |      See `numpy.floor` for more information.\n",
      " |  \n",
      " |  log1p(self)\n",
      " |      Element-wise log1p.\n",
      " |      \n",
      " |      See `numpy.log1p` for more information.\n",
      " |  \n",
      " |  power(self, n, dtype=None)\n",
      " |      This function performs element-wise power.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : n is a scalar\n",
      " |      \n",
      " |      dtype : If dtype is not specified, the current dtype will be preserved.\n",
      " |  \n",
      " |  rad2deg(self)\n",
      " |      Element-wise rad2deg.\n",
      " |      \n",
      " |      See `numpy.rad2deg` for more information.\n",
      " |  \n",
      " |  rint(self)\n",
      " |      Element-wise rint.\n",
      " |      \n",
      " |      See `numpy.rint` for more information.\n",
      " |  \n",
      " |  sign(self)\n",
      " |      Element-wise sign.\n",
      " |      \n",
      " |      See `numpy.sign` for more information.\n",
      " |  \n",
      " |  sin(self)\n",
      " |      Element-wise sin.\n",
      " |      \n",
      " |      See `numpy.sin` for more information.\n",
      " |  \n",
      " |  sinh(self)\n",
      " |      Element-wise sinh.\n",
      " |      \n",
      " |      See `numpy.sinh` for more information.\n",
      " |  \n",
      " |  sqrt(self)\n",
      " |      Element-wise sqrt.\n",
      " |      \n",
      " |      See `numpy.sqrt` for more information.\n",
      " |  \n",
      " |  tan(self)\n",
      " |      Element-wise tan.\n",
      " |      \n",
      " |      See `numpy.tan` for more information.\n",
      " |  \n",
      " |  tanh(self)\n",
      " |      Element-wise tanh.\n",
      " |      \n",
      " |      See `numpy.tanh` for more information.\n",
      " |  \n",
      " |  trunc(self)\n",
      " |      Element-wise trunc.\n",
      " |      \n",
      " |      See `numpy.trunc` for more information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from scipy.sparse._data._data_matrix:\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.sparse._base.spmatrix:\n",
      " |  \n",
      " |  __add__(self, other)\n",
      " |  \n",
      " |  __bool__(self)\n",
      " |  \n",
      " |  __div__(self, other)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattr__(self, attr)\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __iadd__(self, other)\n",
      " |  \n",
      " |  __idiv__(self, other)\n",
      " |  \n",
      " |  __isub__(self, other)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      # What should len(sparse) return? For consistency with dense matrices,\n",
      " |      # perhaps it should be the number of rows?  But for some uses the number of\n",
      " |      # non-zeros is more important.  For now, raise an exception!\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __matmul__(self, other)\n",
      " |  \n",
      " |  __mul__(self, other)\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __nonzero__ = __bool__(self)\n",
      " |  \n",
      " |  __pow__(self, other)\n",
      " |  \n",
      " |  __radd__(self, other)\n",
      " |  \n",
      " |  __rdiv__(self, other)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __rmatmul__(self, other)\n",
      " |  \n",
      " |  __rmul__(self, other)\n",
      " |  \n",
      " |  __rsub__(self, other)\n",
      " |  \n",
      " |  __rtruediv__(self, other)\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  __sub__(self, other)\n",
      " |  \n",
      " |  __truediv__(self, other)\n",
      " |  \n",
      " |  asformat(self, format, copy=False)\n",
      " |      Return this matrix in the passed format.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      format : {str, None}\n",
      " |          The desired matrix format (\"csr\", \"csc\", \"lil\", \"dok\", \"array\", ...)\n",
      " |          or None for no conversion.\n",
      " |      copy : bool, optional\n",
      " |          If True, the result is guaranteed to not share data with self.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A : This matrix in the passed format.\n",
      " |  \n",
      " |  asfptype(self)\n",
      " |      Upcast matrix to a floating point format (if necessary)\n",
      " |  \n",
      " |  conjugate(self, copy=True)\n",
      " |      Element-wise complex conjugation.\n",
      " |      \n",
      " |      If the matrix is of non-complex data type and `copy` is False,\n",
      " |      this method does nothing and the data is not copied.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : bool, optional\n",
      " |          If True, the result is guaranteed to not share data with self.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A : The element-wise complex conjugate.\n",
      " |  \n",
      " |  dot(self, other)\n",
      " |      Ordinary dot product\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import numpy as np\n",
      " |      >>> from scipy.sparse import csr_matrix\n",
      " |      >>> A = csr_matrix([[1, 2, 0], [0, 0, 3], [4, 0, 5]])\n",
      " |      >>> v = np.array([1, 0, -1])\n",
      " |      >>> A.dot(v)\n",
      " |      array([ 1, -3, -1], dtype=int64)\n",
      " |  \n",
      " |  getH(self)\n",
      " |      Return the Hermitian transpose of this matrix.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.matrix.getH : NumPy's implementation of `getH` for matrices\n",
      " |  \n",
      " |  get_shape(self)\n",
      " |      Get shape of a matrix.\n",
      " |  \n",
      " |  getcol(self, j)\n",
      " |      Returns a copy of column j of the matrix, as an (m x 1) sparse\n",
      " |      matrix (column vector).\n",
      " |  \n",
      " |  getformat(self)\n",
      " |      Format of a matrix representation as a string.\n",
      " |  \n",
      " |  getmaxprint(self)\n",
      " |      Maximum number of elements to display when printed.\n",
      " |  \n",
      " |  getrow(self, i)\n",
      " |      Returns a copy of row i of the matrix, as a (1 x n) sparse\n",
      " |      matrix (row vector).\n",
      " |  \n",
      " |  maximum(self, other)\n",
      " |      Element-wise maximum between this and another matrix.\n",
      " |  \n",
      " |  mean(self, axis=None, dtype=None, out=None)\n",
      " |      Compute the arithmetic mean along the specified axis.\n",
      " |      \n",
      " |      Returns the average of the matrix elements. The average is taken\n",
      " |      over all elements in the matrix by default, otherwise over the\n",
      " |      specified axis. `float64` intermediate and return values are used\n",
      " |      for integer inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {-2, -1, 0, 1, None} optional\n",
      " |          Axis along which the mean is computed. The default is to compute\n",
      " |          the mean of all elements in the matrix (i.e., `axis` = `None`).\n",
      " |      dtype : data-type, optional\n",
      " |          Type to use in computing the mean. For integer inputs, the default\n",
      " |          is `float64`; for floating point inputs, it is the same as the\n",
      " |          input dtype.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      out : np.matrix, optional\n",
      " |          Alternative output matrix in which to place the result. It must\n",
      " |          have the same shape as the expected output, but the type of the\n",
      " |          output values will be cast if necessary.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      m : np.matrix\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.matrix.mean : NumPy's implementation of 'mean' for matrices\n",
      " |  \n",
      " |  minimum(self, other)\n",
      " |      Element-wise minimum between this and another matrix.\n",
      " |  \n",
      " |  multiply(self, other)\n",
      " |      Point-wise multiplication by another matrix\n",
      " |  \n",
      " |  nonzero(self)\n",
      " |      nonzero indices\n",
      " |      \n",
      " |      Returns a tuple of arrays (row,col) containing the indices\n",
      " |      of the non-zero elements of the matrix.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from scipy.sparse import csr_matrix\n",
      " |      >>> A = csr_matrix([[1,2,0],[0,0,3],[4,0,5]])\n",
      " |      >>> A.nonzero()\n",
      " |      (array([0, 0, 1, 2, 2]), array([0, 1, 2, 0, 2]))\n",
      " |  \n",
      " |  set_shape(self, shape)\n",
      " |      See `reshape`.\n",
      " |  \n",
      " |  setdiag(self, values, k=0)\n",
      " |      Set diagonal or off-diagonal elements of the array.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : array_like\n",
      " |          New values of the diagonal elements.\n",
      " |      \n",
      " |          Values may have any length. If the diagonal is longer than values,\n",
      " |          then the remaining diagonal entries will not be set. If values are\n",
      " |          longer than the diagonal, then the remaining values are ignored.\n",
      " |      \n",
      " |          If a scalar value is given, all of the diagonal is set to it.\n",
      " |      \n",
      " |      k : int, optional\n",
      " |          Which off-diagonal to set, corresponding to elements a[i,i+k].\n",
      " |          Default: 0 (the main diagonal).\n",
      " |  \n",
      " |  sum(self, axis=None, dtype=None, out=None)\n",
      " |      Sum the matrix elements over a given axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {-2, -1, 0, 1, None} optional\n",
      " |          Axis along which the sum is computed. The default is to\n",
      " |          compute the sum of all the matrix elements, returning a scalar\n",
      " |          (i.e., `axis` = `None`).\n",
      " |      dtype : dtype, optional\n",
      " |          The type of the returned matrix and of the accumulator in which\n",
      " |          the elements are summed.  The dtype of `a` is used by default\n",
      " |          unless `a` has an integer dtype of less precision than the default\n",
      " |          platform integer.  In that case, if `a` is signed then the platform\n",
      " |          integer is used while if `a` is unsigned then an unsigned integer\n",
      " |          of the same precision as the platform integer is used.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      out : np.matrix, optional\n",
      " |          Alternative output matrix in which to place the result. It must\n",
      " |          have the same shape as the expected output, but the type of the\n",
      " |          output values will be cast if necessary.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sum_along_axis : np.matrix\n",
      " |          A matrix with the same shape as `self`, with the specified\n",
      " |          axis removed.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.matrix.sum : NumPy's implementation of 'sum' for matrices\n",
      " |  \n",
      " |  tobsr(self, blocksize=None, copy=False)\n",
      " |      Convert this matrix to Block Sparse Row format.\n",
      " |      \n",
      " |      With copy=False, the data/indices may be shared between this matrix and\n",
      " |      the resultant bsr_matrix.\n",
      " |      \n",
      " |      When blocksize=(R, C) is provided, it will be used for construction of\n",
      " |      the bsr_matrix.\n",
      " |  \n",
      " |  todense(self, order=None, out=None)\n",
      " |      Return a dense matrix representation of this matrix.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : {'C', 'F'}, optional\n",
      " |          Whether to store multi-dimensional data in C (row-major)\n",
      " |          or Fortran (column-major) order in memory. The default\n",
      " |          is 'None', which provides no ordering guarantees.\n",
      " |          Cannot be specified in conjunction with the `out`\n",
      " |          argument.\n",
      " |      \n",
      " |      out : ndarray, 2-D, optional\n",
      " |          If specified, uses this array (or `numpy.matrix`) as the\n",
      " |          output buffer instead of allocating a new array to\n",
      " |          return. The provided array must have the same shape and\n",
      " |          dtype as the sparse matrix on which you are calling the\n",
      " |          method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      arr : numpy.matrix, 2-D\n",
      " |          A NumPy matrix object with the same shape and containing\n",
      " |          the same data represented by the sparse matrix, with the\n",
      " |          requested memory order. If `out` was passed and was an\n",
      " |          array (rather than a `numpy.matrix`), it will be filled\n",
      " |          with the appropriate values and returned wrapped in a\n",
      " |          `numpy.matrix` object that shares the same memory.\n",
      " |  \n",
      " |  tolil(self, copy=False)\n",
      " |      Convert this matrix to List of Lists format.\n",
      " |      \n",
      " |      With copy=False, the data/indices may be shared between this matrix and\n",
      " |      the resultant lil_matrix.\n",
      " |  \n",
      " |  trace(self, offset=0)\n",
      " |      Returns the sum along diagonals of the sparse matrix.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : int, optional\n",
      " |          Which diagonal to get, corresponding to elements a[i, i+offset].\n",
      " |          Default: 0 (the main diagonal).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from scipy.sparse._base.spmatrix:\n",
      " |  \n",
      " |  nnz\n",
      " |      Number of stored values, including explicit zeros.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      count_nonzero : Number of non-zero entries\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from scipy.sparse._base.spmatrix:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  shape\n",
      " |      Get shape of a matrix.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from scipy.sparse._base.spmatrix:\n",
      " |  \n",
      " |  __array_priority__ = 10.1\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  ndim = 2\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.sparse._data._minmax_mixin:\n",
      " |  \n",
      " |  argmax(self, axis=None, out=None)\n",
      " |      Return indices of maximum elements along an axis.\n",
      " |      \n",
      " |      Implicit zero elements are also taken into account. If there are\n",
      " |      several maximum values, the index of the first occurrence is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {-2, -1, 0, 1, None}, optional\n",
      " |          Axis along which the argmax is computed. If None (default), index\n",
      " |          of the maximum element in the flatten data is returned.\n",
      " |      out : None, optional\n",
      " |          This argument is in the signature *solely* for NumPy\n",
      " |          compatibility reasons. Do not pass in anything except for\n",
      " |          the default value, as this argument is not used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ind : numpy.matrix or int\n",
      " |          Indices of maximum elements. If matrix, its size along `axis` is 1.\n",
      " |  \n",
      " |  argmin(self, axis=None, out=None)\n",
      " |      Return indices of minimum elements along an axis.\n",
      " |      \n",
      " |      Implicit zero elements are also taken into account. If there are\n",
      " |      several minimum values, the index of the first occurrence is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {-2, -1, 0, 1, None}, optional\n",
      " |          Axis along which the argmin is computed. If None (default), index\n",
      " |          of the minimum element in the flatten data is returned.\n",
      " |      out : None, optional\n",
      " |          This argument is in the signature *solely* for NumPy\n",
      " |          compatibility reasons. Do not pass in anything except for\n",
      " |          the default value, as this argument is not used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |       ind : numpy.matrix or int\n",
      " |          Indices of minimum elements. If matrix, its size along `axis` is 1.\n",
      " |  \n",
      " |  max(self, axis=None, out=None)\n",
      " |      Return the maximum of the matrix or maximum along an axis.\n",
      " |      This takes all elements into account, not just the non-zero ones.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {-2, -1, 0, 1, None} optional\n",
      " |          Axis along which the sum is computed. The default is to\n",
      " |          compute the maximum over all the matrix elements, returning\n",
      " |          a scalar (i.e., `axis` = `None`).\n",
      " |      \n",
      " |      out : None, optional\n",
      " |          This argument is in the signature *solely* for NumPy\n",
      " |          compatibility reasons. Do not pass in anything except\n",
      " |          for the default value, as this argument is not used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      amax : coo_matrix or scalar\n",
      " |          Maximum of `a`. If `axis` is None, the result is a scalar value.\n",
      " |          If `axis` is given, the result is a sparse.coo_matrix of dimension\n",
      " |          ``a.ndim - 1``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      min : The minimum value of a sparse matrix along a given axis.\n",
      " |      numpy.matrix.max : NumPy's implementation of 'max' for matrices\n",
      " |  \n",
      " |  min(self, axis=None, out=None)\n",
      " |      Return the minimum of the matrix or maximum along an axis.\n",
      " |      This takes all elements into account, not just the non-zero ones.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {-2, -1, 0, 1, None} optional\n",
      " |          Axis along which the sum is computed. The default is to\n",
      " |          compute the minimum over all the matrix elements, returning\n",
      " |          a scalar (i.e., `axis` = `None`).\n",
      " |      \n",
      " |      out : None, optional\n",
      " |          This argument is in the signature *solely* for NumPy\n",
      " |          compatibility reasons. Do not pass in anything except for\n",
      " |          the default value, as this argument is not used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      amin : coo_matrix or scalar\n",
      " |          Minimum of `a`. If `axis` is None, the result is a scalar value.\n",
      " |          If `axis` is given, the result is a sparse.coo_matrix of dimension\n",
      " |          ``a.ndim - 1``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      max : The maximum value of a sparse matrix along a given axis.\n",
      " |      numpy.matrix.min : NumPy's implementation of 'min' for matrices\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(coo_matrix(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce569bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n"
     ]
    }
   ],
   "source": [
    "print(coo_matrix(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "10160e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  27,   27,   27,   27,   27,   27,   27,   27,   27,   27,   27,   27,\n",
       "            27,   27,   27,   27,   27,   27,   27,   27,   27,   27,   27,   27,\n",
       "            27,   27,   27,   27,   27,   27,   27,   27,   27,   27,   27,   27,\n",
       "            27,   27,   27,   27,   27,   27,   27,   27,   27,   27,   27,   27,\n",
       "            27,   27,   27,   27,   27,   27,   27,   27,   27,   27,   27,   27,\n",
       "            27,   27,   27,   27,   27,   27,   27,   27,   27,   27,   27,   27,\n",
       "            27,   27,   27,   27,   27,   27,   27,   27,   27,   27,   27,   27,\n",
       "            27,   27,   27,   27,   27,   27,   27,   27,   27,   27,   27,   27,\n",
       "            27,   27,   27,   27,   27,   27,   27,   27,   27,   27,   27,   27,\n",
       "            27,   27,   27,  309,  309,  309,  309,  309,  309,  309,  309,  309,\n",
       "           309,  309,  309,  309,  309,  309,  309,  309,  309,  309,  309,  309,\n",
       "           309,  309,  309,  309,  309,  309,  309,  309,  309,  309,  309,  309,\n",
       "           309,  309,  309,  309,  309,  309,  309,  309,  309,  309,  309,  309,\n",
       "           309,  309,  309,  309,  309,  309,  309,  309,  309,  309,  309,  309,\n",
       "           309,  309,  309,  309,  309,  309,  309,  309,  309,  309,  309,  309,\n",
       "           309,  309,  309,  309,  309,  309,  309,  309,  309,  418,  418,  418,\n",
       "           418,  418,  418,  418,  418,  418,  418,  418,  418,  418,  418,  418,\n",
       "           418,  418,  418,  418,  418,  418,  418,  418,  418,  418,  418,  418,\n",
       "           418,  418,  418,  418,  418,  418,  418,  418,  418,  418,  418,  418,\n",
       "           418,  418,  418,  418,  418,  418,  418,  418,  418,  418,  418,  418,\n",
       "           418,  418,  418,  418,  418,  418,  418,  418,  418,  418,  473,  473,\n",
       "           473,  473,  473,  473,  473,  473,  473,  473,  473,  473,  473,  473,\n",
       "           473,  473,  473,  473,  473,  473,  473,  473,  473,  473,  473,  473,\n",
       "           473,  473,  473,  473,  473,  473,  473,  473,  473,  473,  473,  473,\n",
       "           473,  473,  473,  473,  473,  473,  473,  473,  473,  473,  473,  473,\n",
       "           473,  473,  473,  473,  473,  496,  496,  496,  496,  496,  496,  496,\n",
       "           496,  496,  496,  496,  496,  496,  496,  496,  496,  496,  496,  496,\n",
       "           496,  496,  496,  496,  496,  496,  496,  496,  496,  496,  496,  496,\n",
       "           496,  496,  496,  496,  496,  496,  496,  496,  496,  496,  496,  496,\n",
       "           496,  496,  496,  496,  496,  496,  496,  496,  496,  511,  511,  511,\n",
       "           511,  511,  511,  511,  511,  511,  511,  511,  511,  511,  511,  511,\n",
       "           511,  511,  511,  511,  511,  511,  511,  511,  511,  511,  511,  511,\n",
       "           511,  511,  511,  511,  511,  511,  511,  511,  511,  511,  511,  511,\n",
       "           511,  511,  511,  511,  511,  511,  511,  511,  511,  511,  511,  511,\n",
       "           681,  681,  681,  681,  681,  681,  681,  681,  681,  681,  681,  681,\n",
       "           681,  681,  681,  681,  681,  681,  681,  681,  681,  681,  681,  681,\n",
       "           681,  681,  720,  720,  720,  720,  720,  720,  720,  720,  720,  720,\n",
       "           720,  720,  720,  720,  720,  720,  720,  720,  720,  720,  720,  720,\n",
       "           720,  720,  720],\n",
       "         [  37,   40,   45,   51,   58,   64,   79,   88,  104,  105,  113,  135,\n",
       "           158,  159,  162,  173,  174,  180,  185,  186,  202,  215,  225,  229,\n",
       "           231,  252,  254,  267,  269,  303,  304,  306,  309,  310,  321,  327,\n",
       "           328,  333,  344,  352,  369,  377,  378,  382,  383,  393,  395,  412,\n",
       "           416,  418,  443,  455,  460,  464,  466,  473,  481,  491,  496,  511,\n",
       "           527,  534,  540,  550,  558,  562,  587,  596,  597,  603,  604,  615,\n",
       "           619,  629,  634,  637,  642,  647,  660,  671,  672,  673,  674,  675,\n",
       "           681,  720,  762,  765,  782,  792,  812,  828,  850,  865,  877,  881,\n",
       "           908,  911,  914,  920,  924,  942,  946,  962,  968,  974,  975,  978,\n",
       "           991, 1012, 1021,  310,  321,  327,  328,  333,  344,  352,  369,  377,\n",
       "           378,  382,  383,  393,  395,  412,  416,  418,  443,  455,  460,  464,\n",
       "           466,  473,  481,  491,  496,  511,  527,  534,  540,  550,  558,  562,\n",
       "           587,  596,  597,  603,  604,  615,  619,  629,  634,  637,  642,  647,\n",
       "           660,  671,  672,  673,  674,  675,  681,  720,  762,  765,  782,  792,\n",
       "           812,  828,  850,  865,  877,  881,  908,  911,  914,  920,  924,  942,\n",
       "           946,  962,  968,  974,  975,  978,  991, 1012, 1021,  443,  455,  460,\n",
       "           464,  466,  473,  481,  491,  496,  511,  527,  534,  540,  550,  558,\n",
       "           562,  587,  596,  597,  603,  604,  615,  619,  629,  634,  637,  642,\n",
       "           647,  660,  671,  672,  673,  674,  675,  681,  720,  762,  765,  782,\n",
       "           792,  812,  828,  850,  865,  877,  881,  908,  911,  914,  920,  924,\n",
       "           942,  946,  962,  968,  974,  975,  978,  991, 1012, 1021,  481,  491,\n",
       "           496,  511,  527,  534,  540,  550,  558,  562,  587,  596,  597,  603,\n",
       "           604,  615,  619,  629,  634,  637,  642,  647,  660,  671,  672,  673,\n",
       "           674,  675,  681,  720,  762,  765,  782,  792,  812,  828,  850,  865,\n",
       "           877,  881,  908,  911,  914,  920,  924,  942,  946,  962,  968,  974,\n",
       "           975,  978,  991, 1012, 1021,  511,  527,  534,  540,  550,  558,  562,\n",
       "           587,  596,  597,  603,  604,  615,  619,  629,  634,  637,  642,  647,\n",
       "           660,  671,  672,  673,  674,  675,  681,  720,  762,  765,  782,  792,\n",
       "           812,  828,  850,  865,  877,  881,  908,  911,  914,  920,  924,  942,\n",
       "           946,  962,  968,  974,  975,  978,  991, 1012, 1021,  527,  534,  540,\n",
       "           550,  558,  562,  587,  596,  597,  603,  604,  615,  619,  629,  634,\n",
       "           637,  642,  647,  660,  671,  672,  673,  674,  675,  681,  720,  762,\n",
       "           765,  782,  792,  812,  828,  850,  865,  877,  881,  908,  911,  914,\n",
       "           920,  924,  942,  946,  962,  968,  974,  975,  978,  991, 1012, 1021,\n",
       "           720,  762,  765,  782,  792,  812,  828,  850,  865,  877,  881,  908,\n",
       "           911,  914,  920,  924,  942,  946,  962,  968,  974,  975,  978,  991,\n",
       "          1012, 1021,  762,  765,  782,  792,  812,  828,  850,  865,  877,  881,\n",
       "           908,  911,  914,  920,  924,  942,  946,  962,  968,  974,  975,  978,\n",
       "           991, 1012, 1021]]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1], dtype=torch.int32))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.from_scipy_sparse_matrix(coo_matrix(npy[:, :, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1451e72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (27, 37)\t1\n",
      "  (27, 40)\t1\n",
      "  (27, 45)\t1\n",
      "  (27, 51)\t1\n",
      "  (27, 58)\t1\n",
      "  (27, 64)\t1\n",
      "  (27, 79)\t1\n",
      "  (27, 88)\t1\n",
      "  (27, 104)\t1\n",
      "  (27, 105)\t1\n",
      "  (27, 113)\t1\n",
      "  (27, 135)\t1\n",
      "  (27, 158)\t1\n",
      "  (27, 159)\t1\n",
      "  (27, 162)\t1\n",
      "  (27, 173)\t1\n",
      "  (27, 174)\t1\n",
      "  (27, 180)\t1\n",
      "  (27, 185)\t1\n",
      "  (27, 186)\t1\n",
      "  (27, 202)\t1\n",
      "  (27, 215)\t1\n",
      "  (27, 225)\t1\n",
      "  (27, 229)\t1\n",
      "  (27, 231)\t1\n",
      "  :\t:\n",
      "  (720, 762)\t1\n",
      "  (720, 765)\t1\n",
      "  (720, 782)\t1\n",
      "  (720, 792)\t1\n",
      "  (720, 812)\t1\n",
      "  (720, 828)\t1\n",
      "  (720, 850)\t1\n",
      "  (720, 865)\t1\n",
      "  (720, 877)\t1\n",
      "  (720, 881)\t1\n",
      "  (720, 908)\t1\n",
      "  (720, 911)\t1\n",
      "  (720, 914)\t1\n",
      "  (720, 920)\t1\n",
      "  (720, 924)\t1\n",
      "  (720, 942)\t1\n",
      "  (720, 946)\t1\n",
      "  (720, 962)\t1\n",
      "  (720, 968)\t1\n",
      "  (720, 974)\t1\n",
      "  (720, 975)\t1\n",
      "  (720, 978)\t1\n",
      "  (720, 991)\t1\n",
      "  (720, 1012)\t1\n",
      "  (720, 1021)\t1\n"
     ]
    }
   ],
   "source": [
    "print(coo_matrix(npy[:, :, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e85b69dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
       "        27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
       "        27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
       "        27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
       "        27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
       "        27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
       "        27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
       "        27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
       "        27,  27,  27,  27,  27,  27,  27, 309, 309, 309, 309, 309, 309,\n",
       "       309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309,\n",
       "       309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309,\n",
       "       309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309,\n",
       "       309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309,\n",
       "       309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309,\n",
       "       309, 309, 309, 309, 309, 309, 309, 418, 418, 418, 418, 418, 418,\n",
       "       418, 418, 418, 418, 418, 418, 418, 418, 418, 418, 418, 418, 418,\n",
       "       418, 418, 418, 418, 418, 418, 418, 418, 418, 418, 418, 418, 418,\n",
       "       418, 418, 418, 418, 418, 418, 418, 418, 418, 418, 418, 418, 418,\n",
       "       418, 418, 418, 418, 418, 418, 418, 418, 418, 418, 418, 418, 418,\n",
       "       418, 418, 418, 473, 473, 473, 473, 473, 473, 473, 473, 473, 473,\n",
       "       473, 473, 473, 473, 473, 473, 473, 473, 473, 473, 473, 473, 473,\n",
       "       473, 473, 473, 473, 473, 473, 473, 473, 473, 473, 473, 473, 473,\n",
       "       473, 473, 473, 473, 473, 473, 473, 473, 473, 473, 473, 473, 473,\n",
       "       473, 473, 473, 473, 473, 473, 496, 496, 496, 496, 496, 496, 496,\n",
       "       496, 496, 496, 496, 496, 496, 496, 496, 496, 496, 496, 496, 496,\n",
       "       496, 496, 496, 496, 496, 496, 496, 496, 496, 496, 496, 496, 496,\n",
       "       496, 496, 496, 496, 496, 496, 496, 496, 496, 496, 496, 496, 496,\n",
       "       496, 496, 496, 496, 496, 496, 511, 511, 511, 511, 511, 511, 511,\n",
       "       511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511,\n",
       "       511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511,\n",
       "       511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511,\n",
       "       511, 511, 511, 511, 511, 681, 681, 681, 681, 681, 681, 681, 681,\n",
       "       681, 681, 681, 681, 681, 681, 681, 681, 681, 681, 681, 681, 681,\n",
       "       681, 681, 681, 681, 681, 720, 720, 720, 720, 720, 720, 720, 720,\n",
       "       720, 720, 720, 720, 720, 720, 720, 720, 720, 720, 720, 720, 720,\n",
       "       720, 720, 720, 720], dtype=int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coo_matrix(npy[:, :, 0]).row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4dbc5e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  37,   40,   45,   51,   58,   64,   79,   88,  104,  105,  113,\n",
       "        135,  158,  159,  162,  173,  174,  180,  185,  186,  202,  215,\n",
       "        225,  229,  231,  252,  254,  267,  269,  303,  304,  306,  309,\n",
       "        310,  321,  327,  328,  333,  344,  352,  369,  377,  378,  382,\n",
       "        383,  393,  395,  412,  416,  418,  443,  455,  460,  464,  466,\n",
       "        473,  481,  491,  496,  511,  527,  534,  540,  550,  558,  562,\n",
       "        587,  596,  597,  603,  604,  615,  619,  629,  634,  637,  642,\n",
       "        647,  660,  671,  672,  673,  674,  675,  681,  720,  762,  765,\n",
       "        782,  792,  812,  828,  850,  865,  877,  881,  908,  911,  914,\n",
       "        920,  924,  942,  946,  962,  968,  974,  975,  978,  991, 1012,\n",
       "       1021,  310,  321,  327,  328,  333,  344,  352,  369,  377,  378,\n",
       "        382,  383,  393,  395,  412,  416,  418,  443,  455,  460,  464,\n",
       "        466,  473,  481,  491,  496,  511,  527,  534,  540,  550,  558,\n",
       "        562,  587,  596,  597,  603,  604,  615,  619,  629,  634,  637,\n",
       "        642,  647,  660,  671,  672,  673,  674,  675,  681,  720,  762,\n",
       "        765,  782,  792,  812,  828,  850,  865,  877,  881,  908,  911,\n",
       "        914,  920,  924,  942,  946,  962,  968,  974,  975,  978,  991,\n",
       "       1012, 1021,  443,  455,  460,  464,  466,  473,  481,  491,  496,\n",
       "        511,  527,  534,  540,  550,  558,  562,  587,  596,  597,  603,\n",
       "        604,  615,  619,  629,  634,  637,  642,  647,  660,  671,  672,\n",
       "        673,  674,  675,  681,  720,  762,  765,  782,  792,  812,  828,\n",
       "        850,  865,  877,  881,  908,  911,  914,  920,  924,  942,  946,\n",
       "        962,  968,  974,  975,  978,  991, 1012, 1021,  481,  491,  496,\n",
       "        511,  527,  534,  540,  550,  558,  562,  587,  596,  597,  603,\n",
       "        604,  615,  619,  629,  634,  637,  642,  647,  660,  671,  672,\n",
       "        673,  674,  675,  681,  720,  762,  765,  782,  792,  812,  828,\n",
       "        850,  865,  877,  881,  908,  911,  914,  920,  924,  942,  946,\n",
       "        962,  968,  974,  975,  978,  991, 1012, 1021,  511,  527,  534,\n",
       "        540,  550,  558,  562,  587,  596,  597,  603,  604,  615,  619,\n",
       "        629,  634,  637,  642,  647,  660,  671,  672,  673,  674,  675,\n",
       "        681,  720,  762,  765,  782,  792,  812,  828,  850,  865,  877,\n",
       "        881,  908,  911,  914,  920,  924,  942,  946,  962,  968,  974,\n",
       "        975,  978,  991, 1012, 1021,  527,  534,  540,  550,  558,  562,\n",
       "        587,  596,  597,  603,  604,  615,  619,  629,  634,  637,  642,\n",
       "        647,  660,  671,  672,  673,  674,  675,  681,  720,  762,  765,\n",
       "        782,  792,  812,  828,  850,  865,  877,  881,  908,  911,  914,\n",
       "        920,  924,  942,  946,  962,  968,  974,  975,  978,  991, 1012,\n",
       "       1021,  720,  762,  765,  782,  792,  812,  828,  850,  865,  877,\n",
       "        881,  908,  911,  914,  920,  924,  942,  946,  962,  968,  974,\n",
       "        975,  978,  991, 1012, 1021,  762,  765,  782,  792,  812,  828,\n",
       "        850,  865,  877,  881,  908,  911,  914,  920,  924,  942,  946,\n",
       "        962,  968,  974,  975,  978,  991, 1012, 1021], dtype=int32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coo_matrix(npy[:, :, 0]).col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc07d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
